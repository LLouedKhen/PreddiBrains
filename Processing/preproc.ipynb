{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bd1c0951",
   "metadata": {},
   "source": [
    "# PRERPROC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fbbd4b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nibabel as nib\n",
    "import os\n",
    "import subprocess\n",
    "import json\n",
    "import shutil\n",
    "from fsl.wrappers import mcflirt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "0497af9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def DICOM2Nifti(data_path:str, subj:str, sess:str):\n",
    "\n",
    "    subj_path = data_path + '/raw/' + subj + sess\n",
    "\n",
    "    if not os.path.exists(subj_path):\n",
    "        os.makedirs(subj_path)\n",
    "\n",
    "    # unzip the folder PB_subj_sess\n",
    "    from zipfile import ZipFile\n",
    "    ZipFile(subj_path + '.zip').extractall(subj_path)\n",
    "\n",
    "    # get the name of the DICOM folder\n",
    "    dicom_folder = os.listdir(subj_path)\n",
    "\n",
    "    if len(dicom_folder) != 1 : \n",
    "        print(\"Warning multiple dicom folder!\")\n",
    "    else :\n",
    "        # convert the dicom folder to nifti \n",
    "        command = [\"dcm2niix\", \"-z\", \"y\", \"-o\", subj_path, \"-f\", \"%p_%s\",subj_path + '/' + dicom_folder[0]]\n",
    "        try:\n",
    "            subprocess.run(command, check=True)\n",
    "            print(\"Conversion done! :)\")\n",
    "        except subprocess.CalledProcessError as e:\n",
    "            print(f'ERROR : {subj}, {command} ', e)\n",
    "\n",
    "        # remove the .zip and the DICOM\n",
    "        shutil.rmtree(subj_path + '/' + dicom_folder[0])\n",
    "        os.remove(subj_path + '.zip')\n",
    "\n",
    "        # remove the files that do not match the 4D size\n",
    "        nifti_files = [file for file in os.listdir(subj_path) if file[-6:] == 'nii.gz']\n",
    "\n",
    "        for nifti_file in nifti_files : \n",
    "            # identify the run files\n",
    "            filepath = subj_path + '/' + nifti_file\n",
    "            img = nib.load(filepath)\n",
    "            if len(img.shape) >= 4 : \n",
    "                if img.shape[3] < 5 : \n",
    "\n",
    "                    if not os.path.isdir(subj_path.replace('raw', 'trash')):\n",
    "                        os.makedirs(subj_path.replace('raw', 'trash'))\n",
    "\n",
    "                    # move to trash folder nii.gz + json associated\n",
    "                    shutil.move(filepath, filepath.replace('raw', 'trash'))\n",
    "                    shutil.move(filepath[:-6] + 'json', filepath.replace('raw', 'trash')[:-6] + 'json')\n",
    "            else :\n",
    "                continue\n",
    "\n",
    "def extract_usfull_file(data_path:str, subj:str, sess:str,  nb_run=2, nb_echo=3):\n",
    "    subj_folder = data_path + '/' + subj + sess\n",
    "    subj_raw_path = data_path + '/raw/' + subj + sess\n",
    "    trash_folder = data_path + '/trash/' + subj + sess\n",
    "\n",
    "    if not os.path.exists(subj_folder) : \n",
    "        os.makedirs(subj_folder + '/func')\n",
    "        os.makedirs(subj_folder + '/anat')\n",
    "    \n",
    "    # Select the runs files\n",
    "    files = [f for f in os.listdir(subj_raw_path) if f[-6:]=='nii.gz']\n",
    "\n",
    "    # Sorte files\n",
    "    for file in files:\n",
    "        img = nib.load(subj_raw_path + '/' +file)\n",
    "\n",
    "        # Runs\n",
    "        if len(img.shape) >3 :\n",
    "            for i in range(nb_run):\n",
    "                for j in range(nb_echo) : \n",
    "                    if 'run'+ str(i+1) in file :\n",
    "                        if 'e' + str(j+1) in file :\n",
    "                            destination_path = subj_folder + '/func/raw_' + subj + sess + '_run' + str(i+1) + '_e' + str(j+1)\n",
    "                            niigz_file = os.path.join(subj_raw_path, file)\n",
    "                            json_file = os.path.join(subj_raw_path, file[:-6]+'json')\n",
    "\n",
    "                            shutil.move(niigz_file, destination_path + '.nii.gz')\n",
    "                            shutil.move(json_file, destination_path + '.json')\n",
    "        # t1\n",
    "        if 't1_mprage' in file : \n",
    "            destination_path = subj_folder + '/anat/T1_' + subj + sess\n",
    "            niigz_file = os.path.join(subj_raw_path, file)\n",
    "            json_file = os.path.join(subj_raw_path, file[:-6]+'json')\n",
    "\n",
    "            shutil.move(niigz_file, destination_path + '.nii.gz')\n",
    "            shutil.move(json_file, destination_path + '.json')\n",
    "\n",
    "        # not PA and not grey fieldmap\n",
    "        if not '_PA_' in file : \n",
    "            if not 'gre_field_mapping' in file :\n",
    "                file_path = os.path.join(subj_raw_path, file)\n",
    "                destination= os.path.join(trash_folder, file)\n",
    "                shutil.move(file_path, destination)\n",
    "\n",
    "def motion_corr(data_path:str, subj:str, sess:str, nb_echo = 3, nb_run = 2): \n",
    "    output_path = data_path+ '/' + subj + sess + '/preproc' \n",
    "    for r in range(nb_run) :\n",
    "        for e in range(nb_echo) : \n",
    "            output_file = output_path + '/st_mc_' + subj + sess + '_run' + str(r+1) + '_e' + str(e+1)\n",
    "            input_file = output_path + '/st_' + subj + sess + '_run' + str(r+1) + '_e' + str(e+1)+'.nii.gz'\n",
    "            if not os.path.exists(output_file):\n",
    "\n",
    "                try :\n",
    "                    mcflirt(infile=input_file, refvol=0, o=output_file, plots=True, mats=True, dof=6)\n",
    "                    print(f\"Motion Correction done, run {r+1}, echo {e+1}! :)\")\n",
    "\n",
    "                    # trash the .mat file #TODO\n",
    "\n",
    "\n",
    "                except :\n",
    "                    print(f'ERROR : {subj}, run {r+1} mcfilrt')\n",
    "\n",
    "            else : \n",
    "                print('Motion correction already done')\n",
    "\n",
    "def slice_timing_corr(data_path:str, subj:str, sess:str, nb_echo = 3, nb_run = 2): \n",
    "    output_path = data_path + '/' + subj + sess + '/preproc'\n",
    "\n",
    "    if not os.path.exists(output_path):\n",
    "        os.makedirs(output_path)\n",
    "\n",
    "    for r in range(nb_run) :\n",
    "        for e in range(nb_echo) : \n",
    "            output_file = output_path + '/st_' + subj + sess + '_run' + str(r+1) + '_e' + str(e+1)\n",
    "            input_file = data_path + '/' + subj + sess + '/func/raw_' + subj + sess + '_run' + str(r+1) + '_e' + str(e+1)+'.nii.gz'\n",
    "            if not os.path.exists(output_file):\n",
    "                try :\n",
    "                    command = ['slicetimer', '-i', input_file, '-o', output_file,  \"-r\", \"2\", \"--odd\"]\n",
    "                    subprocess.call(command)\n",
    "                    print(f\"Slice Timing Correction done, run {r+1}, echo {e+1}! :)\")\n",
    "\n",
    "                except subprocess.CalledProcessError as err:\n",
    "                    print(f'ERROR : {subj}, {r+1}', err)\n",
    "\n",
    "            else : \n",
    "                print('Slice Timing correction already done')\n",
    "    \n",
    "def combine_echo(data_path:str, subj:str, sess:str, nb_run=2, nb_echo=3):\n",
    "    preproc_path= data_path + '/' + subj + sess + '/preproc'\n",
    "    subjpath=data_path + '/' + subj + sess\n",
    "\n",
    "    # combine runs\n",
    "    for i in range(nb_run):\n",
    "        outputdir_run = preproc_path + '/tedana' + '/run' + str(i+1)\n",
    "\n",
    "        if not os.path.isdir(outputdir_run):\n",
    "            os.makedirs(outputdir_run)\n",
    "\n",
    "        time = []\n",
    "        for e in  range(nb_echo) :\n",
    "            jsonfile_path = subjpath + '/func/'+ f'raw_{subj}_run{i+1}_e{e+1}.json'\n",
    "            with open(jsonfile_path, 'r') as jfile:\n",
    "                json_file = json.load(jfile)\n",
    "                time.append(json_file[\"EchoTime\"]*1000)\n",
    "\n",
    "        run = [preproc_path + f'/st_mc_{subj}_run{i+1}_e{e+1}.nii.gz' for e in range(nb_echo)]\n",
    "\n",
    "        command = f'tedana -d {\" \".join(run)} -e {\" \".join(map(str, time))} --out-dir {outputdir_run}'\n",
    "        print(command)\n",
    "        try : \n",
    "            subprocess.call(command, shell=True)  \n",
    "            print('Tedana done! :)')\n",
    "            \n",
    "            # move the output that we are interested in \n",
    "            file = preproc_path +'/tedana/run' + str(i+1) + '/desc-optcom_bold.nii.gz'\n",
    "            destination_file = preproc_path + '/run' + str(i+1) + '/tedana_' +subj + sess + '_run' + str(i+1) + '.nii.gz'\n",
    "            shutil.move(file, destination_file)\n",
    "\n",
    "        except subprocess.CalledProcessError as err:\n",
    "            print(f'ERROR : {subj}, {command}', err)\n",
    "\n",
    "    # rest goes to trash\n",
    "    if not os.path.isdir(data_path + '/trash/' + subj + sess) : \n",
    "        os.makedirs(data_path + '/trash/' + subj + sess)\n",
    "\n",
    "    shutil.move(preproc_path +'/tedana', data_path + '/trash/' + subj + sess)\n",
    "\n",
    "def normalize2anat(data_path:str, subj:str, sess:str, nb_run=2) : \n",
    "    preproc_path = data_path +'/preproc/' + subj + sess \n",
    "    anat_file = data_path + '/' + subj + sess + '/anat/T1_' + subj + sess\n",
    "\n",
    "    for i in range(nb_run) :\n",
    "        # Compute mean volume \n",
    "        mean_func = preproc_path + '/run' + str(i+1) + f'/mean_{subj}{sess}_run{str(i)}.nii.gz'\n",
    "        input_file = preproc_path + '/run' + str(i+1) + f'/tedana_{subj}{sess}_run{str(i+1)}.nii.gz'\n",
    "\n",
    "        if not os.path.exists(mean_func):\n",
    "            command = ['fslmaths', input_file, '-Tmean', mean_func]\n",
    "            try : \n",
    "                subprocess.run(command)\n",
    "                print('fslmaths command done! :)')\n",
    "            except subprocess.CalledProcessError as err:\n",
    "                print(f'ERROR : {subj}, {command}', err)\n",
    "\n",
    "        output_mean_reg_T1 = preproc_path + '/run' + str(i+1) + f'/mean_func_in_T1_{subj}{sess}_run{i+1}.nii.gz'\n",
    "        mat_func_to_T1 = preproc_path + '/run' + str(i+1)+ f'/func_to_T1_{subj}{sess}_run{i+1}.mat'\n",
    "\n",
    "        if not os.path.exists(output_mean_reg_T1) : \n",
    "            flirt_command = ['flirt', '-in', mean_func, '-ref', anat_file,\n",
    "                                '-out', output_mean_reg_T1, '-omat', mat_func_to_T1,\n",
    "                                '-dof', '6']\n",
    "            try :\n",
    "                subprocess.run(flirt_command)\n",
    "                print('Flirt command done! :)')\n",
    "            except subprocess.CalledProcessError as err:\n",
    "                print(f'ERROR : {subj}, {command}', err)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "b1edcd06",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = '/Users/barbaragrosjean/Desktop/CHUV/PreddiBrains/data'\n",
    "subj = 'PB_001'\n",
    "sess = '' "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb5df9a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tedana processing ...\n",
      "tedana -d /Users/barbaragrosjean/Desktop/CHUV/PreddiBrains/data/PB_001/preproc/st_mc_PB_001_run1_e1.nii.gz /Users/barbaragrosjean/Desktop/CHUV/PreddiBrains/data/PB_001/preproc/st_mc_PB_001_run1_e2.nii.gz /Users/barbaragrosjean/Desktop/CHUV/PreddiBrains/data/PB_001/preproc/st_mc_PB_001_run1_e3.nii.gz -e 13.2 34.4 55.58 --out-dir /Users/barbaragrosjean/Desktop/CHUV/PreddiBrains/data/PB_001/preproc/tedana/run1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO     tedana:tedana_workflow:596 Using output directory: /Users/barbaragrosjean/Desktop/CHUV/PreddiBrains/data/PB_001/preproc/tedana/run1\n",
      "INFO     tedana:tedana_workflow:615 Initializing and validating component selection tree\n",
      "WARNING  component_selector:validate_tree:146 Decision tree includes fields that are not used or logged ['_comment']\n",
      "INFO     component_selector:__init__:333 Performing component selection with tedana_orig_decision_tree\n",
      "INFO     component_selector:__init__:334 Very similar to the decision tree designed by Prantik Kundu\n",
      "INFO     tedana:tedana_workflow:618 Loading input data: ['/Users/barbaragrosjean/Desktop/CHUV/PreddiBrains/data/PB_001/preproc/st_mc_PB_001_run1_e1.nii.gz', '/Users/barbaragrosjean/Desktop/CHUV/PreddiBrains/data/PB_001/preproc/st_mc_PB_001_run1_e2.nii.gz', '/Users/barbaragrosjean/Desktop/CHUV/PreddiBrains/data/PB_001/preproc/st_mc_PB_001_run1_e3.nii.gz']\n"
     ]
    }
   ],
   "source": [
    "print(\"Tedana processing ...\")\n",
    "combine_echo(data_path, subj, sess)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8783aff5",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Normalization processing ...\") #to T1\n",
    "normalize2anat(data_path, subj, sess)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "imaging",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
